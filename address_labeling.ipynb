{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification of Smart Contracts\n",
    "- a) Separate EOA & Smart Contracts \n",
    "    - A multisig has no outgoing transactions \n",
    "    - It can have creation event but no necessarily (i.e. proxy contract controls EOA)\n",
    "        - see 1: Contract creation event - https://etherscan.io/address/0x8392f6669292fa56123f71949b52d883ae57e225\n",
    "        - see 2: Doesn't have contract creation event - https://etherscan.io/address/0x9e2b6378ee8ad2a4a95fe481d63caba8fb0ebbf9\n",
    "- b) Filter out Multisigs \n",
    "- c) Classify remaining smart contracts using  ABI, bytecode, return values, and manual code review.\n",
    "    \n",
    "> Ref.: https://ieeexplore.ieee.org/document/9730412\n",
    "\n",
    "> Ref.: https://arxiv.org/pdf/2106.15497.pdf \n",
    "\n",
    "> Ref.: https://ieeexplore.ieee.org/document/9019682 \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EOA Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/eisermann/.local/lib/python3.9/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.2' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/user/eisermann/.local/lib/python3.9/site-packages/pandas/core/arrays/masked.py:59: UserWarning: Pandas requires version '1.3.2' or newer of 'bottleneck' (version '1.2.1' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "from os.path import join\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  \n",
    "\n",
    "path = os.environ['PROJECT_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name=['hash', 'nonce', \"block_hash\",'block_number',\"transaction_index\",'from_address', 'to_address', 'value', 'gas', 'gas_price',\"input\",'block_timestamp', \"max_fee_per_gas\",\"max_priority_fee_per_gas\",\"transaction_type\"]\n",
    "dd_tx = dd.read_csv(join(path,'tx_all_uniq_addresses2.csv'), dtype='str', header=None, names=col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### set-up ###\n",
      "### Start work ###\n",
      "Data written to /local/scratch/exported/governance-erc20/project_erc20_governanceTokens_data/smart_contract_code.csv\n",
      "### End work ###\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The purpose of this script is to collect smart contract code which is neede to classify\n",
    "a) if we are dealing with an EOA addresss\n",
    "b) if we are dealing with a multi-sig \n",
    "c) potentially other identifiable contract\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import dotenv\n",
    "from os.path import join\n",
    "import csv\n",
    "env_var = dotenv.dotenv_values()\n",
    "from web3 import Web3, HTTPProvider\n",
    "\n",
    "\n",
    "print(\"### set-up ###\")\n",
    "# Set up authentication \n",
    "path = env_var[\"PROJECT_PATH\"]\n",
    "w3 = Web3(Web3.HTTPProvider(env_var['INFURA_API_ENDPOINT']))\n",
    "\n",
    "# set input & output path\n",
    "input_path = join(path, 'df_unique_addresses2.csv') \n",
    "output_path = join(path,'smart_contract_code.csv')\n",
    "\n",
    "# load input file\n",
    "df_ua = pd.read_csv(input_path)\n",
    "\n",
    "# Script\n",
    "print(\"### Start work ###\")\n",
    "\n",
    "# Open the CSV file for writing\n",
    "with open(output_path, \"w\", newline=\"\") as csvfile:\n",
    "    fieldnames = ['address', 'code']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for a in df_ua.unique_addresses: \n",
    "\n",
    "        address = w3.toChecksumAddress(a)\n",
    "\n",
    "        code = w3.eth.getCode(address)\n",
    "\n",
    "        writer.writerow({'address': address, 'code':code})\n",
    "\n",
    "        break\n",
    "\n",
    "\n",
    "print(f\"Data written to {output_path}\")\n",
    "print(\"### End work ###\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dd_tx = dd.read_csv(join(path,'transactions_merged_all.csv'), dtype='str')\n",
    "# dd_tx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smart Contract Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External sources of address labeling "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lp pair addresses\n",
    "> Note: For simplification we assume a balanced LP pool of 50-50. \n",
    "\n",
    "1. Filter LP address that are in our set of addresses \n",
    "2. Extract all holder of LP Pool share token\n",
    "3. Sum balances of LP share token for snapshot date \n",
    "4. Divide by 2 \n",
    "5. Add to balances of direct wallet holdings of a given token at snapshot height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ua = pd.read_csv(join(path, 'df_unique_addresses2.csv'))\n",
    "df_ua.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df_lp_pairs = pd.read_csv('assets/address_labels/dex_lp_pair_addresses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lp_pairs['pair_address_f'] = df_lp_pairs['hex(pair_address)'].apply(lambda x: w3.toChecksumAddress('0x' + x))\n",
    "df_ua['unique_addresses_f'] = df_ua.unique_addresses.apply(lambda x: w3.toChecksumAddress(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lp_pairs_relevant = df_lp_pairs[df_lp_pairs.pair_address_f.isin(df_ua.unique_addresses_f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merged df include lp pair data if relevant\n",
    "df_ua.merge(df_lp_pairs_relevant, left_on='unique_addresses_f', right_on='pair_address_f', how='outer', suffixes=('','dex'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
